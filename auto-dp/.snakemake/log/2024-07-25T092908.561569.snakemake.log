Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	all
	1	band_diagram
	1	band_diagram_latextopdf
	1	c_compilation
	1	colored_dbn
	3	compact_dottopdf
	1	concatenation
	1	decomposition_scheme
	1	dot_process
	1	extract_compact_tree
	1	extract_compact_tree_letters
	1	extract_elimination_ordering
	1	extract_tree_equations
	1	extremities_label
	1	pdflatex_dec
	1	pdflatex_equations
	1	produce_latex_equations
	1	state_of_the_results
	1	textopdf
	21
Resources before job selection: {'_cores': 1, '_nodes': 9223372036854775807}
Ready jobs (9):
	band_diagram
	decomposition_scheme
	dot_process
	extract_compact_tree_letters
	c_compilation
	extract_elimination_ordering
	extract_compact_tree
	extract_tree_equations
	extremities_label
Selected jobs (1):
	extremities_label
Resources after job selection: {'_cores': 0, '_nodes': 9223372036854775806}

[Thu Jul 25 09:29:08 2024]
rule extremities_label:
    input: results/processed_td_files/processed_C5.td, results/helix_annotations/C5.helix
    output: results/json_files/extremities_label_C5.json
    jobid: 27
    wildcards: family=C5

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /home/remipoul/LIX_WORK/pwb/auto-dp/.snakemake/log/2024-07-25T092908.561569.snakemake.log
unlocking
removing lock
removing lock
removed all locks
